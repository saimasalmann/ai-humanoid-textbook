---
title: Glossary
description: Definitions of robotics and AI terminology used in this textbook
sidebar_position: 2
learning_objectives:
  - Understand key robotics terminology
  - Define AI and machine learning terms in robotics context
  - Explain common acronyms and abbreviations
  - Apply terminology correctly in robotics discussions
---

# Glossary

## Learning Objectives

After reviewing this glossary, you will be able to:

1. Understand key robotics terminology
2. Define AI and machine learning terms in robotics context
3. Explain common acronyms and abbreviations
4. Apply terminology correctly in robotics discussions

## A

**Action Space**: The set of all possible actions that an agent or robot can take in an environment.

**Actuator**: A mechanical device that converts energy (typically electrical) into physical motion, such as motors, servos, or pneumatic cylinders.

**Affordance**: The possibility of an action that an object provides to an agent; for example, a handle affords grasping.

**Artificial Intelligence (AI)**: The simulation of human intelligence processes by machines, especially computer systems, including learning, reasoning, and self-correction.

**Autonomous System**: A system that operates independently without human intervention, making decisions based on its programming and sensor inputs.

## B

**Behavior Tree**: A hierarchical structure used to organize and execute robot behaviors, commonly used in robotics for task planning and execution.

**Biomechanics**: The study of the structure, function, and motion of the mechanical aspects of biological systems, especially the human body.

**Bipedal Locomotion**: Walking on two legs, a key challenge in humanoid robotics.

## C

**Cartesian Space**: The 3D space defined by X, Y, and Z coordinates, used to describe positions and orientations in the physical world.

**Cognitive Robotics**: A branch of robotics that examines the intersection of robotics and cognitive science, focusing on robots that can think and learn.

**Collision Detection**: The computational problem of detecting the intersection of two or more objects in space, essential for robot safety.

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world, using digital images and deep learning models.

**Control Loop**: A feedback mechanism used in control systems where the output is continuously monitored and adjusted to maintain a desired state.

**Convolutional Neural Network (CNN)**: A class of deep neural networks commonly applied to visual imagery in robotics applications.

## D

**Deep Learning**: A subset of machine learning based on artificial neural networks with representation learning, used extensively in robotics perception.

**Differential Drive**: A common mobile robot configuration using two independently driven wheels placed on the same axis.

**Digital Twin**: A virtual representation of a physical object or system that can be used for simulation, analysis, and optimization.

**Dynamics**: The study of forces and torques and their effect on motion, essential for robot control and simulation.

## E

**Embodied AI**: Artificial intelligence that is integrated with a physical robot, enabling interaction with the real world.

**End Effector**: The device at the end of a robotic arm designed to interact with the environment, such as a gripper or tool.

**Episodic Memory**: Memory of autobiographical events (times, places, associated emotions, etc.) that can be explicitly stated.

**Ethical AI**: The application of AI systems in a way that is fair, transparent, and accountable, with consideration for human values.

## F

**Forward Kinematics**: The use of joint parameters to compute the configuration of the kinematic chain endpoint in robotics.

**Fused Reality**: A mixed reality approach that combines real and virtual elements in a coherent environment.

## G

**Gazebo**: An open-source 3D robotics simulator that provides accurate physics simulation and convenient programmatic interfaces.

**General Artificial Intelligence (AGI)**: AI that can understand, learn, and apply knowledge across a wide range of tasks at a human level.

**Geometric Reasoning**: The ability to understand and interpret spatial relationships and geometric properties.

**GPU Acceleration**: The use of graphics processing units to accelerate computational tasks, especially important in robotics perception and learning.

## H

**Haptic Feedback**: The use of touch and motion to communicate with a user, important in robot teleoperation.

**Heuristic**: A practical approach not guaranteed to be optimal but sufficient for solving problems in a reasonable timeframe.

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots, focusing on design and implementation of robotic systems.

**Humanoid Robot**: A robot with human-like form and capabilities, designed to interact in human environments.

## I

**Inverse Kinematics**: The mathematical process of determining the joint parameters needed to place the end effector at a desired position and orientation.

**Isaac Sim**: NVIDIA's robotics simulation application based on NVIDIA Omniverse, providing high-fidelity physics simulation.

**Isaac ROS**: GPU-accelerated perception and navigation algorithms from NVIDIA for robotics applications.

## J

**Joint Space**: The space defined by the joint angles of a robot, as opposed to Cartesian space.

**Jacobian Matrix**: A matrix of partial derivatives that describes the relationship between joint velocities and end-effector velocities.

## K

**Kinematics**: The study of motion without considering the forces that cause it, essential for robot motion planning.

**Kinesthetic Teaching**: A method of teaching robots by physically guiding them through motions.

## L

**Large Language Model (LLM)**: A language model with many parameters trained on large text corpora, increasingly used for robot task planning.

**Laser Range Finder (LRF)**: A device that measures distances using laser technology, commonly used for robot navigation.

**Latent Space**: A lower-dimensional space that captures the essential features of high-dimensional data, used in robotics learning.

**Legged Locomotion**: The ability to move using legs, a challenging problem in humanoid robotics.

**LiDAR**: Light Detection and Ranging, a remote sensing method using light in the form of a pulsed laser to measure distances.

**Long Short-Term Memory (LSTM)**: A type of recurrent neural network architecture used for sequence prediction problems in robotics.

## M

**Manipulation**: The ability to purposefully control the physical movement of objects, a key capability for humanoid robots.

**Mobile Robot**: A robot that can move around in its environment, as opposed to fixed-arm robots.

**Model Predictive Control (MPC)**: An advanced method of process control that uses a model of the system to predict future behavior.

**Motion Planning**: The computational problem of finding a valid sequence of movements for a robot to reach a goal.

## N

**Navigation**: The ability of a robot to move through an environment, typically involving path planning and obstacle avoidance.

**Neural Network**: A computing system inspired by the human brain, used extensively in robotics for perception and control.

**Non-holonomic Constraint**: A constraint on a robot's motion that cannot be integrated to a constraint on position alone.

## O

**Obstacle Avoidance**: The capability of a robot to detect and navigate around obstacles in its environment.

**Omnidirectional Drive**: A robot drive system that can move in any direction regardless of the direction it's facing.

**Omniverse**: NVIDIA's simulation and collaboration platform for 3D design workflows, including Isaac Sim.

**Ontology**: A formal representation of knowledge as a set of concepts within a domain and the relationships between them.

**Open Source Robotics Foundation (OSRF)**: The organization that develops and maintains Gazebo and other open-source robotics tools.

## P

**Path Planning**: The computational process of finding a sequence of valid positions from a starting position to a goal position.

**Perception**: The ability of a robot to interpret sensory information from its environment.

**Physical AI**: AI systems that interact with and operate in the physical world, combining perception, reasoning, and action.

**Point Cloud**: A set of data points in space, typically generated by 3D scanners or LiDAR sensors.

**Probabilistic Robotics**: The application of probability theory to robotics problems, particularly useful for handling uncertainty.

**Programming by Demonstration (PbD)**: A method of robot programming where the robot learns tasks by observing human demonstrations.

## Q

**Quaternion**: A mathematical concept used to represent rotations in 3D space, commonly used in robotics for orientation.

## R

**Reactive Robot**: A robot that responds directly to sensory input without complex planning, following simple if-then rules.

**Reinforcement Learning (RL)**: A type of machine learning where an agent learns to make decisions by receiving rewards or penalties.

**Robot Operating System (ROS)**: A flexible framework for writing robot software, providing hardware abstraction and device drivers.

**Robotics Middleware**: Software that provides common services and capabilities for robotics applications, like ROS.

**ROS 2**: The second generation of the Robot Operating System, designed for production robotics applications.

**RRT (Rapidly-exploring Random Tree)**: A motion planning algorithm that builds a space-filling tree to find paths in high-dimensional spaces.

## S

**Sensor Fusion**: The process of combining data from multiple sensors to improve the accuracy and reliability of information.

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location.

**Social Robot**: A robot that interacts with humans in a socially acceptable way, often with human-like features.

**Simulation-to-Reality Gap**: The difference between robot performance in simulation and in the real world.

**State Estimation**: The process of estimating the internal state of a system from noisy measurements.

**Supervised Learning**: A machine learning approach where the model is trained on labeled data with known inputs and outputs.

## T

**Task Planning**: The process of decomposing high-level goals into sequences of primitive actions.

**Teleoperation**: The remote operation of a robot, typically with human control over the robot's actions.

**TensorRT**: NVIDIA's inference optimizer and runtime for deep learning models, used in robotics applications.

**Trajectory Planning**: The process of creating a time-parameterized path that describes how a robot should move through space.

## U

**Unstructured Environment**: An environment that lacks predefined organization or structure, challenging for robot navigation.

**Unity**: A real-time 3D development platform that can be used for robotics visualization and simulation.

**URDF (Unified Robot Description Format)**: An XML format for representing robot models in ROS.

## V

**VLA (Vision-Language-Action)**: Systems that integrate visual perception, language understanding, and action execution in robotics.

**Vision System**: A robot system that uses cameras and image processing to perceive its environment.

**Virtual Reality (VR)**: A simulated experience that can be similar to or completely different from the real world, used in robotics training.

## W

**Whole-Body Control**: A control approach that considers the entire robot body when generating control commands.

**Wheeled Mobile Robot**: A robot that moves using wheels, the most common type of mobile robot.

## X, Y, Z

**Zero Moment Point (ZMP)**: A concept used in robotics and biomechanics to assess the stability of legged robots during locomotion.

## Acronyms and Abbreviations

- **AGI**: Artificial General Intelligence
- **API**: Application Programming Interface
- **CNN**: Convolutional Neural Network
- **DDS**: Data Distribution Service
- **GPU**: Graphics Processing Unit
- **HRI**: Human-Robot Interaction
- **IoT**: Internet of Things
- **LIDAR**: Light Detection and Ranging
- **LLM**: Large Language Model
- **LSTM**: Long Short-Term Memory
- **MPC**: Model Predictive Control
- **NLP**: Natural Language Processing
- **PbD**: Programming by Demonstration
- **PDDL**: Planning Domain Definition Language
- **QoS**: Quality of Service
- **ROS**: Robot Operating System
- **RRT**: Rapidly-exploring Random Tree
- **SLAM**: Simultaneous Localization and Mapping
- **URDF**: Unified Robot Description Format
- **VLA**: Vision-Language-Action
- **VR**: Virtual Reality
- **XR**: Extended Reality

## Summary

This glossary provides definitions for key terms used throughout the Physical AI & Humanoid Robotics textbook. Understanding this terminology is essential for effective communication in robotics and AI research and development. The terms cover fundamental concepts in robotics, AI, perception, control, and human-robot interaction.

## Exercises

1. Define the difference between forward and inverse kinematics in your own words
2. Explain how SLAM enables robot autonomy in unknown environments
3. Describe the significance of the simulation-to-reality gap in robotics development

## References

1. Siciliano, B., & Khatib, O. (2016). "Springer Handbook of Robotics". Springer.
2. Corke, P. (2017). "Robotics, Vision and Control: Fundamental Algorithms In MATLAB". Springer.
3. Murphy, R. R. (2019). "Introduction to AI Robotics". MIT Press.
4. Thrun, S., et al. (2005). "Probabilistic Robotics". MIT Press.
5. Open Robotics. (2023). "ROS Glossary". Retrieved from http://wiki.ros.org/
6. IEEE Standards Association. (2023). "IEEE Standards Dictionary of Electrical and Electronics Terms".
7. Khatib, O., et al. (2016). "Robotics: Science and Systems". MIT Press.
8. Chen, W., et al. (2022). "A survey of embodied AI: From robots to large language models". arXiv preprint arXiv:2209.15428.

## Safety Disclaimer

When implementing robotics systems based on terminology from this glossary, ensure that safety considerations are paramount. Many robotics terms relate to systems that interact with humans and physical environments, requiring careful attention to safety protocols and risk mitigation strategies.